<!--    AMCV CVPR 2020  -->

<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

             <td style="padding:20px;width:25%;vertical-align:middle">
              
                  <img src='beyond-flipping.gif' width="160">
              
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              
                <papertitle>Adversarial Fooling beyond Flipping the Label</papertitle>
              
              <br>
              <strong>Konda Reddy Mopuri*</strong>,
              <a href="https://vaisakh-shaj.github.io/">Vaisakh Shaj*</a>,
              <a href="http://cds.iisc.ac.in/faculty/venky/">R. Venkatesh Babu</a>
              <br>
        <em>AMLCV, CVPR</em>, 2020  
              <br>
              <a href="https://openaccess.thecvf.com/content_CVPRW_2020/papers/w47/Mopuri_Adversarial_Fooling_Beyond_Flipping_the_Label_CVPRW_2020_paper.pdf">PDF</a>
              <p></p>
              <p>Analyzes the adversarial attacks beyond fooling rate. Existing metrics only look at the percentage of label flips, but we propose metrics to measure 
              the attack's ability on visual and semantic scales.</p>
            </td>
          </tr> 

 </tbody></table>


<!--    ICVGIP 2018  -->

<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

            <td style="padding:20px;width:25%;vertical-align:middle">
              
                  <img src='batchout.JPG' width="160">
              
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              
                <papertitle>BatchOut: Batch-level feature augmentation to improve robustness to adversarial examples</papertitle>
              
              <br>
              Akshayvarun Subramanya,
              <strong>Konda Reddy Mopuri</strong>,              
              <a href="http://cds.iisc.ac.in/faculty/venky/">R. Venkatesh Babu</a>
              <br>
        <em>ICVGIP</em>, 2018  
              <br>
              <!-- PDF, GitHub, Project page, etc. go here  -->
              <p></p>
              <p>Performs feature space Augmentation to learn  robust deep NNs. In other words, performs efficient Adversarial Training in feature domain
                      unlike the expensive image space.</p>
            </td>
          </tr> 

 </tbody></table>


<!--    ECCV 2018 (A) -->

<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

            <td style="padding:20px;width:25%;vertical-align:middle">
              
                  <img src='gat.jpg' width="160">
              
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              
                <papertitle>GAT: Gray-box Adversarial Training</papertitle>
              
              <br>
              Vivek B S,
              <strong>Konda Reddy Mopuri</strong>,              
              <a href="http://cds.iisc.ac.in/faculty/venky/">R. Venkatesh Babu</a>
              <br>
        <em>ECCV</em>, 2018  
              <br>
              <a href="https://openaccess.thecvf.com/content_ECCV_2018/papers/Vivek_B_S_Gray_box_adversarial_ECCV_2018_paper.pdf">PDF</a>
              <p></p>
              <p>We have demonstrated that the pseudo-robustness of the adversarially trained models is due to the shortcomings of the existing evaluation procedure. 
                 To improve the evaluation, we presented an evaluation procedure via constructing robustness plots and a derived metric (Worst-case Performance) that 
                 can assess the susceptibility of the learned models. Further, harnessing our observations we propose a novel variant of adversarial training, termed 
                 Gray-box Adversarial Training to learn robust models.</p>
            </td>
          </tr> 

 </tbody></table>
